import os
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin,urlparse
import re
from tqdm import tqdm



def download_site(url, output_dir, logger, file_types):
    logger.info(f"D√©marrage du t√©l√©chargement pour : {url}")

    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        logger.info(f"path not exists : {output_dir}")
        logger.info(f"creat path : {output_dir}")

    try:
        response = requests.get(url)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")

      
        main_page = os.path.join(output_dir, "index.html")
        with open(main_page, "w", encoding="utf-8") as f:
            f.write(soup.prettify())
        logger.info(f"Page principale enregistr√©e : {main_page}")

       
        resources = []
        for tag, attr in [("link", "href"), ("script", "src"), ("img", "src")]:
            for resource in soup.find_all(tag):
                if attr in resource.attrs:
                    resource_url = urljoin(url, resource[attr])
                    if any(resource_url.endswith(f".{ext}") for ext in file_types):
                        resources.append(resource_url)

        print(f"\nüîÑ T√©l√©chargement de {len(resources)} ressources associ√©es :\n")
        for resource_url in tqdm(resources, desc="T√©l√©chargement des ressources", unit="fichier"):
            download_resource(resource_url, output_dir, logger)

    except requests.RequestException as e:
        logger.error(f"Erreur de requ√™te : {e}")
        raise
    logger.info("T√©l√©chargement termin√©.")




def download_resource(resource_url, output_dir, logger):
    try:
        logger.info(f"T√©l√©chargement de la ressource : {resource_url}")
        response = requests.get(resource_url, stream=True)
        response.raise_for_status()

        parsed_url = urlparse(resource_url)
        filename = os.path.basename(parsed_url.path)
        if not filename or "?" in filename or "&" in filename:
            filename = re.sub(r'[^a-zA-Z0-9_.-]', '_', parsed_url.path)
        filename = filename[:255]



        file_path = os.path.join(output_dir, filename)

      
        total_size = int(response.headers.get('content-length', 0))
        with open(file_path, "wb") as f:
            for chunk in response.iter_content(1024):
                f.write(chunk)

        logger.info(f"Ressource t√©l√©charg√©e avec succ√®s : {file_path}")
    except requests.RequestException as e:
        logger.warning(f"√âchec du t√©l√©chargement : {resource_url} - {e}")
    except Exception as e:
        logger.error(f"Erreur lors du t√©l√©chargement : {e}")
